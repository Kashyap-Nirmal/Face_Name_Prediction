{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0.XGBoost_Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Download the XGBoost model trained on Indian Face Name dataset**"
      ],
      "metadata": {
        "id": "1auCVAeK_4md"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Kashyap-Nirmal/indian-face-name-prediction"
      ],
      "metadata": {
        "id": "oNCJPAc8ATSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing necessary libraries**"
      ],
      "metadata": {
        "id": "Oee4YuBu-S2M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLoFWQZ4rGj4"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import cv2\n",
        "import keras\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "import math\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature extraction using Spatial Pyramid Pooling**"
      ],
      "metadata": {
        "id": "wYTw0hWN_CH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # example of tending the vgg16 model\n",
        "\n",
        "# load model without classifier layers\n",
        "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(64, 64, 3))\n",
        "\n",
        "win1 = math.ceil(16/1)\n",
        "str1 = math.floor(16/1)\n",
        "\n",
        "win2 = math.ceil(16/2)\n",
        "str2 = math.floor(16/2)\n",
        "\n",
        "win3 = math.ceil(16/4)\n",
        "str3 = math.floor(16/4)\n",
        "\n",
        "l1 = keras.layers.MaxPooling2D(pool_size=(win1), strides=str1, padding=\"valid\")(base_model.layers[-10].output)\n",
        "l2 = keras.layers.MaxPooling2D(pool_size=(win2), strides=str2, padding=\"valid\")(base_model.layers[-10].output)\n",
        "l3 = keras.layers.MaxPooling2D(pool_size=(win3), strides=str3, padding=\"valid\")(base_model.layers[-10].output)\n",
        "\n",
        "flat1 = Flatten()(l1)\n",
        "flat2 = Flatten()(l2)\n",
        "flat3 = Flatten()(l3)\n",
        "\n",
        "# # define new model\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model = Model(inputs=base_model.inputs, outputs=[flat1, flat2, flat3])"
      ],
      "metadata": {
        "id": "gt_zIJhwyMO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the saved XGBoost model**"
      ],
      "metadata": {
        "id": "5Cf1R7qB-bh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_cl1 = xgb.XGBClassifier()\n",
        "booster = xgb.Booster()\n",
        "booster.load_model(\"/content/indian-face-name-prediction/Model_XGB_Indian.json\")\n",
        "xgb_cl1._Booster = booster;\n",
        "xgb_cl1._le = LabelEncoder().fit([\"Krishna\", \"Pranav\", \"Priya\", \"Rahul\", \"Sonal\"])"
      ],
      "metadata": {
        "id": "9zsuvIrGraOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Please insert the Test image path here**"
      ],
      "metadata": {
        "id": "unC-YZL-_AOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_file = '/content/rahul gate compressed pic 300px - 2021 11035.jpg'"
      ],
      "metadata": {
        "id": "ACCZejYZtpY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing the image suited for XGBoost**"
      ],
      "metadata": {
        "id": "1gLJNo2o_TlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the image to detect faces in\n",
        "img = cv2.imread(test_file)\n",
        "img = cv2.resize(img, (256, 256))\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Detect Faces\n",
        "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "face_coordinates = faceCascade.detectMultiScale(\n",
        "        gray,\n",
        "        scaleFactor=1.3,          \n",
        "        minSize=(30, 30)\n",
        "    )   \n",
        "\n",
        "img_crop = []\n",
        "test_file1 = []\n",
        "\n",
        "for (x, y, w, h) in face_coordinates:\n",
        "    img_crop.append(img[y:y + h, x:x + w])\n",
        "\n",
        "for counter, cropped in enumerate(img_crop):\n",
        "    name = test_file.split('.')\n",
        "    output_filename = name[0]+\"_Crop_\"+ str(counter) + \".jpg\"    \n",
        "    test_file1.append(output_filename)\n",
        "    cv2.resize(cropped,(256,256))\n",
        "    cv2.imwrite(output_filename, cropped)\n",
        "    cv2.waitKey(0)    "
      ],
      "metadata": {
        "id": "UjZOhCK6Oa1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predicting the Test image**"
      ],
      "metadata": {
        "id": "X1OkmqUO-iQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_name = []\n",
        "\n",
        "cnt = 1\n",
        "for i in test_file1 :  \n",
        "        test_file_X = []\n",
        "        try:\n",
        "            image = cv2.imread(i)\n",
        "            image = cv2.resize(image, (64, 64))\n",
        "            image = img_to_array(image)\n",
        "            test_file_X.append(image)\n",
        "            test_file_X = np.array(test_file_X, dtype=\"float\")/255.0\n",
        "            img_test = model.predict(test_file_X)\n",
        "            img_test = np.hstack([img_test[0], img_test[1], img_test[2]])        \n",
        "            list_name.append(xgb_cl1.predict(img_test)[0])            \n",
        "            cnt += 1\n",
        "\n",
        "            #Generating pseudo random number to show the random guess vs Output of the model\n",
        "            #random.seed(random.randint(0,1000))            \n",
        "            #n = random.randint(0,4)\n",
        "            label = {\"Krishna\":0, \"Pranav\":1, \"Priya\":2, \"Rahul\":3, \"Sonal\": 4}\n",
        "            key_list = list(label.keys())\n",
        "            #print(\"\\nRandom guess is : \"+key_list[n])\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(e)"
      ],
      "metadata": {
        "id": "SE2JB2-dSHNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Name_Association():\n",
        "    # Choose an image to detect faces in\n",
        "    img = cv2.imread(test_file)\n",
        "    img = cv2.resize(img, (256, 256))\n",
        "    name = test_file.split('.')\n",
        "    output_filename = name[0]+\"_Resized.jpg\"    \n",
        "    img = cv2.imwrite(output_filename, img)\n",
        "\n",
        "    img = cv2.imread(test_file)\n",
        "    img = cv2.resize(img, (256, 256))\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect Faces\n",
        "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "    face_coordinates = faceCascade.detectMultiScale(\n",
        "            gray,\n",
        "            scaleFactor=1.3,          \n",
        "            minSize=(30, 30)\n",
        "        )   \n",
        "\n",
        "    # fontScale\n",
        "    fontScale = 0.5\n",
        "    \n",
        "    # Font Color in BGR\n",
        "    color = (255, 0, 0)\n",
        "    \n",
        "    # Line thickness in px\n",
        "    thickness = 2\n",
        "\n",
        "    cnt = 0\n",
        "\n",
        "    for (x, y, w, h) in face_coordinates:    \n",
        "        name = list_name[cnt]\n",
        "        cnt += 1\n",
        "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "        font = cv2.FONT_HERSHEY_COMPLEX\n",
        "        fontScale = (x+y)/100\n",
        "        fontScale = 1\n",
        "        if(fontScale>1):\n",
        "            fontScale = 0.95    \n",
        "        image = cv2.putText(img, name, (x+2,y), font, \n",
        "                    fontScale, color, thickness, cv2.LINE_AA)\n",
        "        \n",
        "    name = test_file.split('.')\n",
        "    output_filename = name[0]+\"_Name_Association_\"+ str(counter) + \".jpg\"    \n",
        "\n",
        "    status = cv2.imwrite(output_filename, img)\n",
        "    mpshow = mpimg.imread(output_filename)\n",
        "    plt.imshow(mpshow)\n",
        "    print(\"\\nTotal number of faces detected : \"+ str(len(img_crop))+\"\\n\\nOutput image with names associated is as below\\n\")\n",
        "    plt.show()\n",
        "                \n",
        "    if(len(test_file1) == 0) :\n",
        "        print(\"Sorry. No face detected. Please insert other image.\")\n",
        "        \n",
        "    else:\n",
        "        cnt = 0\n",
        "        print(\"\\nCropped faces from the input image are as below.\")\n",
        "        for i in test_file1 :  \n",
        "            test_file_X = []\n",
        "            try:\n",
        "                image = cv2.imread(i)\n",
        "                image = cv2.resize(image, (64, 64))\n",
        "                image = img_to_array(image)\n",
        "                test_file_X.append(image)\n",
        "                test_file_X = np.array(test_file_X, dtype=\"float\")/255.0\n",
        "                img_test = model.predict(test_file_X)\n",
        "                img_test = np.hstack([img_test[0], img_test[1], img_test[2]])        \n",
        "                mpshow = mpimg.imread(i)\n",
        "                plt.imshow(mpshow)            \n",
        "                print(\"\\nFace \"+ str(cnt+1)+\" : \"+list_name[cnt]+\"\\n\")\n",
        "                plt.show()\n",
        "                cnt += 1\n",
        "            \n",
        "            except Exception as e:\n",
        "                print(e)   "
      ],
      "metadata": {
        "id": "B9Rmkk_4GBRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(len(list_name) != 0):\n",
        "    Name_Association()\n",
        "else :\n",
        "    print(\"Sorry. No face detected. Please insert other image.\")"
      ],
      "metadata": {
        "id": "TDOaWw_e9g27"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
